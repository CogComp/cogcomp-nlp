From http://www.cis.upenn.edu/~dbikel/software.html#comparator

Randomized Parsing Evaluation Comparator (Statistical Significance
Tester for evalb Output)
Author: Dan Bikel

A persistent problem with parsing—particularly with English—is that of
repeatedly evaluating on the same test set, noting increases in
evaluation metrics like labeled bracket recall and precision, but not
knowing if those differences are statistically significant (there is
another, perhaps more serious problem with repeatedly evaluating on
the same test set, but don’t get me started on that here). To address
this issue, I have written a short Perl script that reads that output
of evalb on two different parsing runs and outputs p-values for
whether observed differences in recall and/or precision are
statistically significant.

The test employed is a type of “stratified shuffling” (which in turn
is a type of “compute-intensive randomized test”). In this testing
method, the null hypothesis is that the two models that produced the
observed results are the same, such that for each test instance
(sentence that was parsed), the two observed scores are equally
likely. This null hypothesis is tested by randomly shuffling
individual sentences’ scores between the two models and then
re-computing the evaluation metrics (precision and recall, in this
case). If the difference in a particular metric after a shuffling is
equal to or greater than the original observed difference in that
metric, then a counter for that metric is incremented. Ideally, one
would perform all 2n shuffles, where n is the number of test cases
(sentences), but given that this is often prohibitively expensive, the
default number of iterations is 10,000. After all iterations, the
likelihood of incorrectly rejecting the null is simply (nc + 1)/(nt +
1), where nc is the number of random differences greater than the
original observed difference, and nt is the total number of
iterations.

Caveat: This type of testing method assumes independence between test
instances (sentences). This is not a bad assumption for parsing
results, but is not correct, either.

Warning: the script is provided as is; use at your own risk (although
it can’t really harm anything to try it out).

